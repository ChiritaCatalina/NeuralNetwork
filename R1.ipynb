{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alecs\\Anaconda3\\envs\\CChirita\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: val_loss,loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.7777586]] [[6.04]] [[1.3475518]]\n",
      "[[10.966237]] [[12.06]] [[0.90074736]]\n",
      "[[8.917921]] [[13.84]] [[0.6154625]]\n",
      "[[8.426732]] [[15.77]] [[0.5014754]]\n",
      "[[8.052368]] [[6.62]] [[1.2566967]]\n",
      "[[8.526323]] [[11.44]] [[0.7198388]]\n",
      "[[8.051502]] [[10.]] [[0.78253376]]\n",
      "[[9.552823]] [[11.]] [[0.85470104]]\n",
      "[[8.575297]] [[9.56]] [[0.8844245]]\n",
      "[[8.6562605]] [[11.61]] [[0.7205544]]\n",
      "[[11.819885]] [[14.73]] [[0.78742766]]\n",
      "[[11.090614]] [[13.]] [[0.84035236]]\n",
      "[[9.106158]] [[8.51]] [[1.079807]]\n",
      "[[12.571946]] [[8.4]] [[1.5668405]]\n",
      "[[9.73076]] [[11.41]] [[0.8380674]]\n",
      "[[11.389873]] [[9.44]] [[1.2321277]]\n",
      "[[8.333223]] [[8.13]] [[1.0286634]]\n",
      "[[10.602466]] [[12.]] [[0.8724877]]\n",
      "[[9.596745]] [[10.]] [[0.9549937]]\n",
      "[[12.571946]] [[8.4]] [[1.5668405]]\n",
      "[[9.7761135]] [[10.]] [[0.9750126]]\n",
      "[[9.770062]] [[8.22]] [[1.2158861]]\n",
      "[[8.160122]] [[7.47]] [[1.1073284]]\n",
      "[[9.893909]] [[14.]] [[0.683172]]\n",
      "[[8.779063]] [[15.92]] [[0.52009827]]\n",
      "[[8.904214]] [[8.]] [[1.1299157]]\n",
      "[[13.029065]] [[11.]] [[1.2037213]]\n",
      "[[10.238515]] [[8.65]] [[1.2087404]]\n",
      "[[10.151815]] [[7.4]] [[1.4326754]]\n",
      "[[8.286123]] [[9.]] [[0.910317]]\n",
      "[[9.486485]] [[14.75]] [[0.616082]]\n",
      "[[9.3523445]] [[9.41]] [[0.99311167]]\n",
      "[[10.243008]] [[14.]] [[0.7101086]]\n",
      "[[11.6754055]] [[12.]] [[0.97038364]]\n",
      "[[11.832167]] [[15.46]] [[0.74841654]]\n",
      "[[9.477215]] [[15.17]] [[0.5971135]]\n",
      "[[10.577967]] [[9.05]] [[1.1907573]]\n",
      "[[11.303279]] [[7.84]] [[1.5093056]]\n",
      "[[10.840013]] [[9.89]] [[1.107346]]\n",
      "[[9.103032]] [[13.13]] [[0.6669174]]\n",
      "[[9.826485]] [[13.71]] [[0.6934873]]\n",
      "[[11.13982]] [[7.89]] [[1.4744262]]\n",
      "[[9.590649]] [[13.68]] [[0.67647535]]\n",
      "[[8.610398]] [[13.84]] [[0.59143734]]\n",
      "[[8.670626]] [[13.]] [[0.6380121]]\n",
      "[[9.985869]] [[13.3]] [[0.72967935]]\n",
      "[[8.209088]] [[7.19]] [[1.1657056]]\n",
      "[[9.636869]] [[5.65]] [[1.8648305]]\n",
      "[[9.219026]] [[9.18]] [[1.0047942]]\n",
      "[[13.42187]] [[14.]] [[0.9553912]]\n",
      "errmin,errmax,x4: [[0.5014754]] [[1.5668405]] 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_excel(r'Copy of Extraction PT4 14x59 din 2016 pana in prezent - analysis S1928 (003) (3).xlsx', sheet_name='TL4 -40 Nm' )\n",
    "dataset = df.values\n",
    "X = dataset[1:,23:42]\n",
    "Y = dataset[1:,14]\n",
    "X = X.astype('float')\n",
    "Y = Y.astype('float')\n",
    "\n",
    "\n",
    "d1 = pd.DataFrame(X)\n",
    "d2 = pd.DataFrame(Y)\n",
    "d1.drop([1,3,5,7,8,9,10,11,13,15,17], axis=1, inplace=True)\n",
    "d2.replace(0.  , np.nan, inplace=True)\n",
    "d2.replace(-1. , np.nan, inplace=True)\n",
    "d2.replace(1.  , np.nan, inplace=True)\n",
    "d2.replace(2.  , np.nan, inplace=True)\n",
    "d2.replace(3.  , np.nan, inplace=True)\n",
    "d2.replace(4.  , np.nan, inplace=True)\n",
    "d2.replace(5.  , np.nan, inplace=True)\n",
    "d2.replace(6.  , np.nan, inplace=True)\n",
    "\n",
    "d1[7] = d2[0]\n",
    "d1.dropna(inplace=True)\n",
    "# d1.isnull().any() # Verifica daca avem vre-o valoare de tip NaN\n",
    "\n",
    "X = d1.values[0:,:-1]\n",
    "Y = d1.values[0:, -1:]\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "Y_scaler = preprocessing.MinMaxScaler()\n",
    "Y_scale = Y_scaler.fit_transform(Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y_scale, test_size=0.2)\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def basic_model_3(x):\n",
    "     # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(x, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(x, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(x, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def error(x):\n",
    "    emax = 1.\n",
    "    emin = 1.\n",
    "    for i in range(x):\n",
    "        p = model.predict(X_train[i].reshape(1, 8))\n",
    "        #print(p, Y_train[i], p/float(Y_train[i]))\n",
    "        pp = Y_scaler.inverse_transform(p)\n",
    "        py = Y_scaler.inverse_transform(Y_train[i].reshape(1,-1))\n",
    "        r = p/float(Y_train[i])\n",
    "        if r > emax and py > 7.:\n",
    "            emax = r\n",
    "        if r < emin and py > 7.:\n",
    "            emin = r\n",
    "        print(pp,py, r)\n",
    "    return emin , emax;\n",
    "\n",
    "rmin = 10\n",
    "rmax = 11\n",
    "\n",
    "for x4 in range(rmin,rmax):\n",
    "                dif=3.0\n",
    "                model = basic_model_3(x4)\n",
    "                epochs = 10000\n",
    "                batch_size = 128\n",
    "                #print('Epochs: ', epochs)\n",
    "                #print('Batch size: ', batch_size)\n",
    "                keras_callbacks = [\n",
    "                # ModelCheckpoint('/tmp/keras_checkpoints/model.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', save_best_only=True, verbose=2)\n",
    "                # ModelCheckpoint('/tmp/keras_checkpoints/model.{epoch:02d}.hdf5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "                # TensorBoard(log_dir='/tmp/keras_logs/model_3', histogram_freq=0, write_graph=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None),\n",
    "                EarlyStopping(monitor='val_mean_absolute_error', patience=20, verbose=0)\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "                history = model.fit(X_train, Y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                shuffle=True,\n",
    "                verbose=0, # Change it to 2, if wished to observe execution\n",
    "                validation_data=(X_test, Y_test),\n",
    "                callbacks=keras_callbacks)\n",
    "                \n",
    "                train_score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "                valid_score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "            \n",
    "                emn , ema = error(50)\n",
    "                print('errmin,errmax,x4:',emn,ema , x4)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('k.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?range\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
