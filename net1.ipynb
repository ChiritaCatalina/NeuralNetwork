{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model de predictie multiparametru\n",
    "\n",
    "Modelul nostru citeste un fisier Excel si imparte datele de intrare in elemente de intrare si elemente de iesire. Elementele de intrare au 24 de caracteristici pe care le urmeaza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (918, 22), Y: (918,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r'Copy of Extraction PT4 14x59 din 2016 pana in prezent - analysis S1928 (003).xlsx', sheet_name='TL4 -40 Nm' )\n",
    "dataset = df.values\n",
    "\n",
    "X = dataset[1:,23:45]\n",
    "Y = dataset[1:,14]\n",
    "X = X.astype('float')\n",
    "Y = Y.astype('float')\n",
    "print(\"X:  %s, Y: %s\" % (X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizarea datelor\n",
    "Este necesara extragerea din dataset a valorilor de intrare care au valoare NaN.\n",
    "De asemenea, am ignorat parametrii care nu varieaza in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((910, 21), (910,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdf = pd.DataFrame(X)\n",
    "Ydf = pd.DataFrame(Y)\n",
    "tdat = Xdf\n",
    "tdat[22] = Ydf[0]\n",
    "tdat.dropna(inplace=True)\n",
    "td = tdat.values\n",
    "X = td[1:, 0:21]\n",
    "Y = td[1:, 22]\n",
    "X = X.astype('float')\n",
    "Y = Y.astype('float')\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalam datele de intrare si de iesire intre valorile 0 si 1\n",
    "pentru aceasta apelam la minmaxscaller din pachetul scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 21)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = pd.DataFrame(X_scale)\n",
    "d1.dropna(inplace=True)\n",
    "d1.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impartim datele in data de training si date de test\n",
    "\n",
    "folosind regula 2/3 vs 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637, 21)\n",
      "(136, 21)\n",
      "(137, 21)\n",
      "(637,)\n",
      "(136,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.48051948, 0.20967742, 0.41176471, ..., 0.5       , 0.125     ,\n",
       "         0.19767442],\n",
       "        [0.48051948, 0.24193548, 0.58823529, ..., 0.6       , 0.25      ,\n",
       "         0.12790698],\n",
       "        [0.42857143, 0.19354839, 0.70588235, ..., 0.5       , 0.125     ,\n",
       "         0.39534884],\n",
       "        ...,\n",
       "        [0.32467532, 0.33870968, 0.35294118, ..., 0.4       , 0.125     ,\n",
       "         0.48837209],\n",
       "        [0.36363636, 0.12903226, 0.58823529, ..., 0.3       , 0.125     ,\n",
       "         0.51162791],\n",
       "        [0.05194805, 0.25806452, 0.70588235, ..., 0.4       , 0.25      ,\n",
       "         0.31395349]]),\n",
       " array([ 5.01,  7.13,  8.46, 11.41, 14.95,  7.84, 15.8 , 11.  , 14.73,\n",
       "         7.47,  8.  , 11.6 , 10.83, 11.44,  6.  , 15.77,  5.  ,  6.13,\n",
       "        12.76,  8.64,  4.  , 10.84, 10.22, 10.08,  9.44, 12.88,  7.24,\n",
       "        12.  , 12.75, 12.31,  1.19, 11.  ,  9.34, 11.  ,  5.34,  7.54,\n",
       "        13.27,  3.58, 10.48,  9.1 ,  9.  ,  9.18,  4.98,  8.  , 13.85,\n",
       "         8.22,  6.67,  5.  , 12.12, 10.27, 13.91, 13.4 , 12.68, 14.9 ,\n",
       "        15.  , 13.33,  8.12, 11.32, 13.63, 15.  ,  9.  , 10.62,  9.57,\n",
       "        11.56,  9.71,  0.  ,  2.76, 11.51,  2.  ,  7.  ,  8.46,  9.56,\n",
       "         5.31, 10.3 ,  6.  ,  4.41,  6.  ,  9.23, 17.83, 13.  , 14.  ,\n",
       "        12.  ,  8.58, 14.  ,  9.93,  7.3 , 11.56,  9.1 ,  8.43, 15.  ,\n",
       "        11.02, 13.85, 15.  ,  5.  , 11.  ,  0.  , 12.26,  8.11,  2.6 ,\n",
       "        14.  ,  3.28,  7.89,  8.49, 15.  , 13.91,  8.2 , 16.11, 12.52,\n",
       "         9.52,  4.08, 11.44,  8.  ,  8.  , 12.12, 15.76, 10.26,  8.68,\n",
       "        13.  , 11.  ,  8.75,  2.  , 13.72, 13.  ,  4.66, 13.88, 12.56,\n",
       "        13.  ,  1.  , 11.69, 14.41, 13.12, 13.07, 11.79, 14.58, 15.  ,\n",
       "         6.22,  9.46]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "\n",
    "X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cream modelul ML\n",
    "1 strat de intrare de dimensiunea dictata de numarul de parametrii folositi (22)\n",
    "\n",
    "1 strat ascuns dim 77 folosind modelul de activare ReLU\n",
    "\n",
    "1 strat ascuns dim 77 folosind modelul de activare ReLU\n",
    "\n",
    "1 strat de iesire dim 1 folosind un model de activare de tip sigmoid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 637 samples, validate on 136 samples\n",
      "Epoch 1/100\n",
      "637/637 [==============================] - 2s 3ms/step - loss: 0.0180 - val_loss: 0.0148\n",
      "Epoch 2/100\n",
      "637/637 [==============================] - 0s 155us/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 3/100\n",
      "637/637 [==============================] - 0s 157us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 4/100\n",
      "637/637 [==============================] - 0s 152us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 5/100\n",
      "637/637 [==============================] - 0s 143us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 6/100\n",
      "637/637 [==============================] - 0s 148us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 7/100\n",
      "637/637 [==============================] - 0s 140us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 8/100\n",
      "637/637 [==============================] - 0s 151us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 9/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 10/100\n",
      "637/637 [==============================] - 0s 135us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 11/100\n",
      "637/637 [==============================] - 0s 135us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 12/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 13/100\n",
      "637/637 [==============================] - 0s 140us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 14/100\n",
      "637/637 [==============================] - 0s 135us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 15/100\n",
      "637/637 [==============================] - 0s 126us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 16/100\n",
      "637/637 [==============================] - 0s 132us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 17/100\n",
      "637/637 [==============================] - 0s 126us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 18/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 19/100\n",
      "637/637 [==============================] - 0s 135us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 20/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 21/100\n",
      "637/637 [==============================] - 0s 132us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 22/100\n",
      "637/637 [==============================] - 0s 130us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 23/100\n",
      "637/637 [==============================] - 0s 143us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 24/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 25/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 26/100\n",
      "637/637 [==============================] - 0s 130us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 27/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 28/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 29/100\n",
      "637/637 [==============================] - 0s 137us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 30/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 31/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 32/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 33/100\n",
      "637/637 [==============================] - 0s 135us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 34/100\n",
      "637/637 [==============================] - 0s 532us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 35/100\n",
      "637/637 [==============================] - 0s 432us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 36/100\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.0183    - 0s 177us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 37/100\n",
      "637/637 [==============================] - 0s 159us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 38/100\n",
      "637/637 [==============================] - 0s 157us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 39/100\n",
      "637/637 [==============================] - 0s 141us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 40/100\n",
      "637/637 [==============================] - 0s 149us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 41/100\n",
      "637/637 [==============================] - 0s 166us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 42/100\n",
      "637/637 [==============================] - 0s 179us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 43/100\n",
      "637/637 [==============================] - 0s 166us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 44/100\n",
      "637/637 [==============================] - 0s 157us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 45/100\n",
      "637/637 [==============================] - 0s 155us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 46/100\n",
      "637/637 [==============================] - 0s 173us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 47/100\n",
      "637/637 [==============================] - 0s 140us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 48/100\n",
      "637/637 [==============================] - 0s 155us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 49/100\n",
      "637/637 [==============================] - 0s 176us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 50/100\n",
      "637/637 [==============================] - 0s 157us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 51/100\n",
      "637/637 [==============================] - 0s 157us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 52/100\n",
      "637/637 [==============================] - 0s 159us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 53/100\n",
      "637/637 [==============================] - 0s 163us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 54/100\n",
      "637/637 [==============================] - 0s 124us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 55/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 56/100\n",
      "637/637 [==============================] - 0s 132us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 57/100\n",
      "637/637 [==============================] - 0s 126us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 58/100\n",
      "637/637 [==============================] - 0s 228us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 59/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 60/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 61/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 62/100\n",
      "637/637 [==============================] - 0s 124us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 63/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 64/100\n",
      "637/637 [==============================] - 0s 212us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 65/100\n",
      "637/637 [==============================] - 0s 151us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 66/100\n",
      "637/637 [==============================] - 0s 165us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 67/100\n",
      "637/637 [==============================] - 0s 146us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 68/100\n",
      "637/637 [==============================] - 0s 140us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 69/100\n",
      "637/637 [==============================] - 0s 144us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 70/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 71/100\n",
      "637/637 [==============================] - 0s 132us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 72/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 73/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 74/100\n",
      "637/637 [==============================] - 0s 132us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 75/100\n",
      "637/637 [==============================] - 0s 124us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 76/100\n",
      "637/637 [==============================] - 0s 144us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 77/100\n",
      "637/637 [==============================] - 0s 132us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 78/100\n",
      "637/637 [==============================] - 0s 157us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637/637 [==============================] - 0s 213us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 80/100\n",
      "637/637 [==============================] - 0s 118us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 81/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 82/100\n",
      "637/637 [==============================] - 0s 116us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 83/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 84/100\n",
      "637/637 [==============================] - 0s 143us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 85/100\n",
      "637/637 [==============================] - 0s 138us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 86/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 87/100\n",
      "637/637 [==============================] - 0s 130us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 88/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 89/100\n",
      "637/637 [==============================] - 0s 132us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 90/100\n",
      "637/637 [==============================] - 0s 126us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 91/100\n",
      "637/637 [==============================] - 0s 140us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 92/100\n",
      "637/637 [==============================] - 0s 129us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 93/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 94/100\n",
      "637/637 [==============================] - 0s 130us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 95/100\n",
      "637/637 [==============================] - 0s 133us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 96/100\n",
      "637/637 [==============================] - 0s 124us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 97/100\n",
      "637/637 [==============================] - 0s 118us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 98/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 99/100\n",
      "637/637 [==============================] - 0s 127us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 100/100\n",
      "637/637 [==============================] - 0s 119us/step - loss: 0.0126 - val_loss: 0.0147\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential([\n",
    "    Dense(77, activation='relu', kernel_initializer='uniform', input_shape=(21,)),\n",
    "    Dense(77, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "\n",
    "#model.compile(optimizer='Adadelta', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='hinge')\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#model.compile(optimizer='adam', loss='mean_squared_logarithmic_error')\n",
    "# model.compile(optimizer='rmsprop', loss=\"mean_absolute_percentage_error\")\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=21, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-84d24d69b6e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
